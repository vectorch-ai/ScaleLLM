name: Package test

on:
  workflow_dispatch:

  workflow_call:

  # Schedule the workflow to run at 08:00 (UTC) every day.
  schedule:
    # Minute[0,59] Hour[0,23] Day of month[1,31] Month[1,12] Day of week[0,6] (Sunday=0)
    - cron: '0 8 * * *'

env:
  # Tells where to store caches.
  CI_CACHE_DIR: ${{ github.workspace }}/../../ci_cache

jobs:
  build_wheel:
    strategy:
      fail-fast: false
      matrix:
        python: ["3.9", "3.10", "3.11", "3.12", "3.13"]
        cuda: ["12.8"]
        torch: ["2.8.0"]
    runs-on: [self-hosted, linux]
    env:
      PYTHON_VERSION: ${{ matrix.python }}
      CUDA_VERSION: ${{ matrix.cuda }}
      TORCH_VERSION: ${{ matrix.torch }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        submodules: recursive

    - name: Create cache directory
      run: |
        mkdir -p $CI_CACHE_DIR/.vcpkg/bincache
        mkdir -p $CI_CACHE_DIR/.ccache
        mkdir -p $CI_CACHE_DIR/.pip

    - name: Delete old files
      run: rm -rf dist/*

    - name: Build wheel
      timeout-minutes: 60
      run: |
        docker pull vectorchai/scalellm_manylinux2_28:cuda${CUDA_VERSION}
        docker run --rm -t \
            -v "$CI_CACHE_DIR":/ci_cache \
            -v "$GITHUB_WORKSPACE":/ScaleLLM \
            -e PYTHON_VERSION=${PYTHON_VERSION} \
            -e CUDA_VERSION=${CUDA_VERSION} \
            -e TORCH_VERSION=${TORCH_VERSION} \
            -e VCPKG_DEFAULT_BINARY_CACHE=/ci_cache/.vcpkg/bincache \
            -e CCACHE_DIR=/ci_cache/.ccache \
            -e PIP_CACHE_DIR=/ci_cache/.pip \
            -u $(id -u):$(id -g) \
            vectorchai/scalellm_manylinux2_28:cuda${CUDA_VERSION} \
            bash /ScaleLLM/.ci/scripts/build_wheel.sh

    - name: Show whl package size
      run: du -h dist/*

    - uses: actions/upload-artifact@v4
      with:
        name: scalellm-cuda${{ matrix.cuda }}-torch${{ matrix.torch }}-python${{ matrix.python }}
        path: dist/*

  test_wheel:
    needs: build_wheel
    strategy:
      fail-fast: false
      matrix:
        python: ["3.9", "3.10", "3.11", "3.12", "3.13"]
        cuda: ["12.8"]
        torch: ["2.8.0"]
    runs-on: [self-hosted, linux, gpu]
    env:
      PYTHON_VERSION: ${{ matrix.python }}
      CUDA_VERSION: ${{ matrix.cuda }}
      TORCH_VERSION: ${{ matrix.torch }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Delete old files
        run: rm -rf dist/*

      - name: Download wheel
        uses: actions/download-artifact@v4
        with:
          path: dist
          merge-multiple: true
          pattern: scalellm-cuda${{ matrix.cuda }}-torch${{ matrix.torch }}-python${{ matrix.python }}

      - name: Show whl package size
        run: du -h dist/*

      - name: Install the package and run pytest
        timeout-minutes: 10
        run: |
          docker pull pytorch/manylinux2_28-builder:cuda${CUDA_VERSION}
          docker run --rm -t --gpus=all \
              -v "$CI_CACHE_DIR":/ci_cache \
              -v "$GITHUB_WORKSPACE":/ScaleLLM \
              -e PYTHON_VERSION=${PYTHON_VERSION} \
              -e CUDA_VERSION=${CUDA_VERSION} \
              -e TORCH_VERSION=${TORCH_VERSION} \
              -e PIP_CACHE_DIR=/ci_cache/.pip \
              -u $(id -u):$(id -g) \
              pytorch/manylinux2_28-builder:cuda${CUDA_VERSION} \
              bash /ScaleLLM/.ci/scripts/run_pytest.sh
